

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>CUDA Execution Model &mdash; cuda 1.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="cuda 1.0 documentation" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> cuda
          

          
          </a>

          
            
            
              <div class="version">
                1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="1.html">CUDA Program Structure</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">cuda</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
      <li>CUDA Execution Model</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/source/3.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="cuda-execution-model">
<h1>CUDA Execution Model<a class="headerlink" href="#cuda-execution-model" title="Permalink to this headline">¶</a></h1>
<div class="section" id="gpu-architecture-overview">
<h2>GPU architecture Overview<a class="headerlink" href="#gpu-architecture-overview" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>The GPU architecture is built around a scalable array of Streaming Multiprocessors (SM). GPU hardware parallelism is achieved through the replication of this architectural building block.</li>
<li>CUDA employs a Single Instruction Multiple Thread (SIMT) architecture to manage and execute threads in groups of 32 called warps. All threads in a warp execute the same instruction at the same time. Each thread has its own instruction address counter and register state, and carries out the current instruction on its own data. Each SM partitions the thread blocks assigned to it into 32-thread warps that it then schedules for execution on available hardware resources.</li>
<li>SIMT architecture is similar to the SIMD (Single Instruction, Multiple Data) architecture. Both SIMD and SIMT implement parallelism by broadcasting the same instruction to multiple execution units. A key difference is that SIMD requires that all vector elements in a vector execute together in a unified synchronous group, whereas SIMT allows multiple threads in the same warp to execute independently. Even though all threads in a warp start together at the same program address, it is possible for individual threads to have different behavior. SIMT enables you to write thread-level parallel code for independent, scalar threads, as well as data-parallel code for coordinated threads.</li>
<li>The SIMT model includes three key features that SIMD does not:
Each thread has its own instruction address counter.
Each thread has its own register state.
Each thread can have an independent execution path.</li>
</ul>
<img alt="../_images/GPUArch.png" src="../_images/GPUArch.png" />
</div>
<div class="section" id="streaming-multiprocessor">
<h2>Streaming MultiProcessor<a class="headerlink" href="#streaming-multiprocessor" title="Permalink to this headline">¶</a></h2>
<p>SM: The Heart of GPU architecture</p>
<img alt="../_images/Device_SM.png" src="../_images/Device_SM.png" />
<p>The Streaming Multiprocessor (SM) is the heart of the GPU architecture. Registers and shared memory are scarce resources in the SM. CUDA partitions these resources among all threads resident on an SM. Therefore, these limited resources impose a strict restriction on the number of active warps in an SM, which corresponds to the amount of parallelism possible in an SM. Knowing some basic facts about the hardware components of an SM will help you organize threads and configure kernel execution to get the best performance.</p>
</div>
<div class="section" id="fermi-architecture">
<h2>Fermi Architecture<a class="headerlink" href="#fermi-architecture" title="Permalink to this headline">¶</a></h2>
<p>Figure illustrates a logical block diagram of the Fermi architecture focused on GPU computing with graphics-specific components largely omitted. Fermi features up to 512 accelerator cores, called CUDA cores. Each CUDA core has a fully pipelined integer arithmetic logic unit (ALU) and a floating-point unit (FPU) that executes one integer or floating-point instruction per clock cycle.  The CUDA cores are organized into 16 streaming multiprocessors (SM), each with 32 CUDA cores.  Fermi has six 384-bit GDDR5 DRAM memory interfaces supporting up to a total of 6 GB of global on-board memory, a key compute resource for many applications. A host interface connects the GPU to the CPU via the PCI Express bus. The GigaThread engine (shown in orange on the left side of the diagram) is a global scheduler that distributes thread blocks to the SM warp schedulers.</p>
<img alt="../_images/Fermi_ARCH.png" src="../_images/Fermi_ARCH.png" />
<p>Fermi includes:</p>
<ul class="simple">
<li>a coherent 768KB L2 cache,shared by all 16 SMs.</li>
<li>Each SM (in figure above) is represented by a vertical rectangular strip containing:</li>
<li>Execution units(CUDA cores)</li>
<li>Scheduler and dispatcher units that schedule warps</li>
<li>shared Memory,the register file,and L1 cache.</li>
<li>LD/ST units</li>
<li>SFU(special function units) : execute intrinsic instruction such as sine,cosine,square root,and interpolation</li>
<li>Each SM Features two warp schedulers and two instruction dispatch units.</li>
</ul>
<img alt="../_images/thread_warp_scheduler.png" src="../_images/thread_warp_scheduler.png" />
</div>
<div class="section" id="the-kepler-architecture">
<h2>The Kepler Architecture<a class="headerlink" href="#the-kepler-architecture" title="Permalink to this headline">¶</a></h2>
<p>The Kepler GPU architecture, released in the fall of 2012, is a fast and highly efficient, high-performance computing architecture. Kepler features make hybrid computing even more accessible to you.</p>
<p>Figure illustrates the Kepler K20X chip block diagram, containing 15 streaming multiprocessors (SMs) and six 64-bit memory controllers. Three important innovations in the Kepler architecture are:</p>
<p>➤ Enhanced SMs</p>
<p>➤ Dynamic Parallelism</p>
<p>➤ Hyper-Q</p>
<img alt="../_images/Kepler_arch.png" src="../_images/Kepler_arch.png" />
<img alt="../_images/kepler_SMX.png" src="../_images/kepler_SMX.png" />
</div>
<div class="section" id="important-facts-pertaining-to-compute-capability">
<h2>Important facts Pertaining to Compute Capability<a class="headerlink" href="#important-facts-pertaining-to-compute-capability" title="Permalink to this headline">¶</a></h2>
<img alt="../_images/import_facts1.png" src="../_images/import_facts1.png" />
<img alt="../_images/import_facts2.png" src="../_images/import_facts2.png" />
</div>
<div class="section" id="profile-driven-optimization">
<h2>Profile-Driven Optimization<a class="headerlink" href="#profile-driven-optimization" title="Permalink to this headline">¶</a></h2>
<p>Profiling is the act of analyzing program performance by measuring:</p>
<p>➤ The space (memory) or time complexity of application code</p>
<p>➤ The use of particular instructions</p>
<p>➤ The frequency and duration of function calls</p>
<p>Profiling often requires a basic understanding of the execution model of a platform to help make</p>
<p>application optimization decisions.</p>
<p>Profiling tools provide deep insight into kernel performance and help you identify bottlenecks in</p>
<p>kernels. CUDA provides two primary profiling tools: nvvp, a standalone visual profiler; and nvprof,</p>
<p>a command-line profiler</p>
<ul class="simple">
<li>nvvp</li>
<li>nvprof</li>
<li>nvvp is a Visual Profiler, which helps you to visualize and optimize the performance of your CUDA program. This tool displays a timeline of program activity on both the CPU and GPU, helping you to identify opportunities for performance improvement. In addition, nvvp analyzes your application for potential performance bottlenecks and suggests actions to take to eliminate or reduce those bottlenecks. The tool is available as both a standalone application and as part of the Nsight Eclipse Edition (nsight).</li>
<li>nvprof collects and displays profiling data on the command line. nvprof was introduced with</li>
</ul>
<p>CUDA 5 and evolved from an older command-line CUDA profiling tool. Like nvvp, it enables the</p>
<p>collection of a timeline of CUDA-related activities on both the CPU and GPU, including kernel execution, memory transfers, and CUDA API calls. It also enables you to collect hardware counters and</p>
<p>performance metrics for CUDA kernels.</p>
<img alt="../_images/Know_hw_details.png" src="../_images/Know_hw_details.png" />
</div>
<div class="section" id="understanding-the-nature-of-warp-execution">
<h2>Understanding the nature of warp execution<a class="headerlink" href="#understanding-the-nature-of-warp-execution" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li>This chapter has already covered the concept of grouping 32 threads into a single execution unit: a warp. Now you will take a closer look at warp execution from the hardware perspective, and gain insights that will help guide kernel design.</li>
<li>Warps are the basic unit of execution in an SM. When you launch a grid of thread blocks, the thread blocks in the grid are distributed among SMs. Once a thread block is scheduled to an SM, threads in the thread block are further partitioned into warps. A warp consists of 32 consecutive threads and all threads in a warp are executed in Single Instruction Multiple Thread (SIMT) fashion; that is, all threads execute the same instruction, and each thread carries out that operation on its own private data.</li>
</ul>
<img alt="../_images/warps.png" src="../_images/warps.png" />
<ul class="simple">
<li>Threads in the same warp executing different instructions is referred to as warp divergence. Warp divergence would seem to cause a paradox, as you already know that all threads in a warp must execute the same instruction on each cycle.</li>
<li>Warp divergence can cause significantly degraded performance.</li>
<li>To obtain the best performance, you should avoid different execution paths within the same warp.</li>
<li>If you interleave data using a warp approach (instead of a thread approach), you can avoid warp divergence and achieve 100 percent utilization of the device. The condition (tid/warpSize)%2==0 forces the branch granularity to be a multiple of warp size; the even warps take the if clause, and the odd warps take the else clause. This kernel produces the same output, but in a different order.</li>
<li>You can also directly observe warp divergence by using the nvprof profiler to collect metrics from the GPU. Here, nvprof’s branch_efficiency metric is calculated for a sample execution of simpleDivergence:</li>
</ul>
<blockquote>
<div><div class="highlight-default"><div class="highlight"><pre><span></span>$ nvprof --metrics branch_efficiency ./simpleDivergence
</pre></div>
</div>
</div></blockquote>
<img alt="../_images/warps_2.png" src="../_images/warps_2.png" />
</div>
<div class="section" id="occupancy">
<h2>Occupancy<a class="headerlink" href="#occupancy" title="Permalink to this headline">¶</a></h2>
<p>occupancy is the ratio of active warps to maximum number of warps, per SM.</p>
<blockquote>
<div>occupancy = active warps/maximum warps</div></blockquote>
<p>CHECK YOUR GPU using this file: cuda_gpu_info.cu</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="c1">#include &lt;sys/time.h&gt;</span>
<span class="c1">#include &lt;stdio.h&gt;</span>
<span class="c1">#include &lt;cuda_runtime.h&gt;</span>

<span class="c1">#define CHECK(call)                                                            \</span>
<span class="p">{</span>                                                                              \
    <span class="n">const</span> <span class="n">cudaError_t</span> <span class="n">error</span> <span class="o">=</span> <span class="n">call</span><span class="p">;</span>                                            \
    <span class="k">if</span> <span class="p">(</span><span class="n">error</span> <span class="o">!=</span> <span class="n">cudaSuccess</span><span class="p">)</span>                                                  \
    <span class="p">{</span>                                                                          \
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s2">&quot;Error: </span><span class="si">%s</span><span class="s2">:</span><span class="si">%d</span><span class="s2">, &quot;</span><span class="p">,</span> <span class="n">__FILE__</span><span class="p">,</span> <span class="n">__LINE__</span><span class="p">);</span>                 \
        <span class="n">fprintf</span><span class="p">(</span><span class="n">stderr</span><span class="p">,</span> <span class="s2">&quot;code: </span><span class="si">%d</span><span class="s2">, reason: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">error</span><span class="p">,</span>                       \
                <span class="n">cudaGetErrorString</span><span class="p">(</span><span class="n">error</span><span class="p">));</span>                                    \
    <span class="p">}</span>                                                                          \
<span class="p">}</span>


<span class="o">/*</span>
 <span class="o">*</span> <span class="n">Fetches</span> <span class="n">basic</span> <span class="n">information</span> <span class="n">on</span> <span class="n">the</span> <span class="n">first</span> <span class="n">device</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">current</span> <span class="n">CUDA</span> <span class="n">platform</span><span class="p">,</span>
 <span class="o">*</span> <span class="n">including</span> <span class="n">number</span> <span class="n">of</span> <span class="n">SMs</span><span class="p">,</span> <span class="nb">bytes</span> <span class="n">of</span> <span class="n">constant</span> <span class="n">memory</span><span class="p">,</span> <span class="nb">bytes</span> <span class="n">of</span> <span class="n">shared</span> <span class="n">memory</span> <span class="n">per</span>
 <span class="o">*</span> <span class="n">block</span><span class="p">,</span> <span class="n">etc</span><span class="o">.</span>
 <span class="o">*/</span>

<span class="nb">int</span> <span class="n">main</span><span class="p">(</span><span class="nb">int</span> <span class="n">argc</span><span class="p">,</span> <span class="n">char</span> <span class="o">*</span><span class="n">argv</span><span class="p">[])</span>
<span class="p">{</span>
    <span class="nb">int</span> <span class="n">iDev</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="n">cudaDeviceProp</span> <span class="n">iProp</span><span class="p">;</span>
    <span class="n">CHECK</span><span class="p">(</span><span class="n">cudaGetDeviceProperties</span><span class="p">(</span><span class="o">&amp;</span><span class="n">iProp</span><span class="p">,</span> <span class="n">iDev</span><span class="p">));</span>

    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;Device </span><span class="si">%d</span><span class="s2">: </span><span class="si">%s</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">iDev</span><span class="p">,</span> <span class="n">iProp</span><span class="o">.</span><span class="n">name</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Number of multiprocessors:                     </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">multiProcessorCount</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Total amount of constant memory:               </span><span class="si">%4.2f</span><span class="s2"> KB</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">totalConstMem</span> <span class="o">/</span> <span class="mf">1024.0</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Total amount of shared memory per block:       </span><span class="si">%4.2f</span><span class="s2"> KB</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">sharedMemPerBlock</span> <span class="o">/</span> <span class="mf">1024.0</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Total number of registers available per block: </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">regsPerBlock</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Warp size:                                     </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">warpSize</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Maximum number of threads per block:           </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">maxThreadsPerBlock</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Maximum number of threads per multiprocessor:  </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">maxThreadsPerMultiProcessor</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s2">&quot;  Maximum number of warps per multiprocessor:    </span><span class="si">%d</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span>
           <span class="n">iProp</span><span class="o">.</span><span class="n">maxThreadsPerMultiProcessor</span> <span class="o">/</span> <span class="mi">32</span><span class="p">);</span>
    <span class="k">return</span> <span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>nvcc cuda_gpu_info.cu -o cuda_gpu_info</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">Device</span> <span class="mi">0</span><span class="p">:</span> <span class="n">GeForce</span> <span class="n">GTX</span> <span class="mi">1080</span>
  <span class="n">Number</span> <span class="n">of</span> <span class="n">multiprocessors</span><span class="p">:</span>                     <span class="mi">20</span>
  <span class="n">Total</span> <span class="n">amount</span> <span class="n">of</span> <span class="n">constant</span> <span class="n">memory</span><span class="p">:</span>               <span class="mf">64.00</span> <span class="n">KB</span>
  <span class="n">Total</span> <span class="n">amount</span> <span class="n">of</span> <span class="n">shared</span> <span class="n">memory</span> <span class="n">per</span> <span class="n">block</span><span class="p">:</span>       <span class="mf">48.00</span> <span class="n">KB</span>
  <span class="n">Total</span> <span class="n">number</span> <span class="n">of</span> <span class="n">registers</span> <span class="n">available</span> <span class="n">per</span> <span class="n">block</span><span class="p">:</span> <span class="mi">65536</span>
  <span class="n">Warp</span> <span class="n">size</span><span class="p">:</span>                                     <span class="mi">32</span>
  <span class="n">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span> <span class="n">per</span> <span class="n">block</span><span class="p">:</span>           <span class="mi">1024</span>
  <span class="n">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">threads</span> <span class="n">per</span> <span class="n">multiprocessor</span><span class="p">:</span>  <span class="mi">2048</span>
  <span class="n">Maximum</span> <span class="n">number</span> <span class="n">of</span> <span class="n">warps</span> <span class="n">per</span> <span class="n">multiprocessor</span><span class="p">:</span>    <span class="mi">64</span>
</pre></div>
</div>
<p>The registers per thread and shared memory per block resource usage can be obtained from nvcc with the following compiler flag:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="o">--</span><span class="n">ptxas</span><span class="o">-</span><span class="n">options</span><span class="o">=-</span><span class="n">v</span>
</pre></div>
</div>
<img alt="../_images/guidelines_for_grid_block.png" src="../_images/guidelines_for_grid_block.png" />
<img alt="../_images/sm_block.png" src="../_images/sm_block.png" />
<ul class="simple">
<li>Checking Active Warps with nvprof</li>
</ul>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ nvprof --metrics achieved_occupancy ./sumMatrix 32 32
</pre></div>
</div>
<ul class="simple">
<li>Checking Memory Operations with nvprof</li>
</ul>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ nvprof --metrics gld_throughput./sumMatrix 32 32

sumMatrixOnGPU2D &lt;&lt;&lt;(512,512), (32,32)&gt;&gt;&gt; Global Load Throughput 35.908GB/s

$ nvprof --metrics gld_throughput./sumMatrix 32 16

sumMatrixOnGPU2D &lt;&lt;&lt;(512,1024), (32,16)&gt;&gt;&gt; Global Load Throughput 56.478GB/s

$ nvprof --metrics gld_throughput./sumMatrix 16 32

sumMatrixOnGPU2D &lt;&lt;&lt;(1024,512), (16,32)&gt;&gt;&gt; Global Load Throughput 85.195GB/s

$ nvprof --metrics gld_throughput./sumMatrix 16 16

sumMatrixOnGPU2D &lt;&lt;&lt;(1024,1024),(16,16)&gt;&gt;&gt; Global Load Throughput 94.708GB/s
</pre></div>
</div>
<p>Next, check the global load efficiency using the gld_efficiency metric, which is the ratio of</p>
<p>requested global load throughput to required global load throughput. It measures how well the</p>
<p>application’s load operations use device memory bandwidth. The results are summarized below:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span>$ nvprof --metrics gld_efficiency ./sumMatrix 32 32

sumMatrixOnGPU2D &lt;&lt;&lt;(512,512), (32,32)&gt;&gt;&gt; Global Memory Load Efficiency 100.00%

$ nvprof --metrics gld_efficiency ./sumMatrix 32 16

sumMatrixOnGPU2D &lt;&lt;&lt;(512,1024), (32,16)&gt;&gt;&gt; Global Memory Load Efficiency 100.00%

$ nvprof --metrics gld_efficiency ./sumMatrix 16 32

sumMatrixOnGPU2D &lt;&lt;&lt;(1024,512), (16,32)&gt;&gt;&gt; Global Memory Load Efficiency 49.96%

$ nvprof --metrics gld_efficiency ./sumMatrix 16 16

sumMatrixOnGPU2D &lt;&lt;&lt;(1024,1024),(16,16)&gt;&gt;&gt; Global Memory Load Efficiency 49.80%
</pre></div>
</div>
</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, lijun.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>